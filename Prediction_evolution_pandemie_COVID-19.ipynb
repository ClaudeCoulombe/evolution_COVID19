{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ScDo-Bandeau_Lingua_Technologies.png\" style=\"width: 100%;float:center;\"/>\n",
    "\n",
    "<h1 style=\"font-size:250%;text-align:center\">Prédiction de l'évolution temporelle de la</h1>\n",
    "<h1 style=\"font-size:250%;text-align:center\">pandémie du COVID-19</h1>\n",
    "<h1 style=\"font-size:250%;text-align:center\">modèles prédictifs</h1>\n",
    "<h4 style=\"font-size:150%;text-align:center\">par Claude COULOMBE</h4>\n",
    "<h5 style=\"font-size:100%;text-align:center\">PhD, scientifique de données, consultant Lingua Technologies</h5>\n",
    "\n",
    "\n",
    "<img src=\"images/ScDo-pandas_logo.png\" width=400 />\n",
    "\n",
    "Pour contrer l'anxiété de la pandémie de COVID-19, rien de mieux que d'agir. J'ai donc préparé un petit carnet Web Python, prétexte pour un petit exercice d'exploration de données avec Pandas. Maintenant un petit carnet web IPython avec des modèles prédictifs. \n",
    "\n",
    "**Attention!** Je ne suis pas épidémiologiste! Il s'agit d'un exercice «amateur» réalisé comme un loisir scientifique. Je suis ouvert à la discussion pour améliorer mes modèles et pour le plaisir d'apprendre. Aussi ces modèles ne sont bons que pour faire des prédictions à court terme. Par exemple. pour prédire un cycle épidémique, un modèle ARIMA ou d'ajustement de courbes doit disposer d'au moins un cycle complet de données. \n",
    "\n",
    "Une autre approche consisterait à se baser sur le comportement de l'épidémie en Chine et ajuster les paramètres aux données locales. J'ignore toutefois si cela donnerait des résultats fiables. \n",
    "\n",
    "**Note:** Pour faire des prédictions plus complètes et à plus long terme, des simulations avec des modèles mathématiques à base d'équations différentielles seraient plus appropriées (https://bit.ly/2JEMe3g). D'ailleurs certains paramètres de ces modèles peuvent être extraits des données. Pour avoir une idée du fonctionnment de tels modèles, avec des simulations-jouets, allez voir les capsules vidéos de Grant Sanderson (3Blue1Brown), mon infographiste scientifique préféré: https://bit.ly/33Umjhe\n",
    "\n",
    "<hr style=\"height:1px\">\n",
    "\n",
    "**Références:**\n",
    "\n",
    "COVID-19: Time Series Analysis With ARIMA Modelling<br/>\n",
    "https://bit.ly/2xK3GAI\n",
    "\n",
    "Epidemiology and ARIMA model of positive-rate of influenza viruses among children in Wuhan, China: A nine-year retrospective study<br/>\n",
    "https://bit.ly/3dJAfiJ\n",
    "\n",
    "Application of the ARIMA model on the COVID-2019 epidemic dataset<br/>\n",
    "https://bit.ly/2xMfFNR\n",
    "\n",
    "Forecasting of COVID-19 Confirmed Cases in Different Countries with ARIMA Models<br/>\n",
    "https://bit.ly/2UTRe9b\n",
    "\n",
    "<hr style=\"height:1px\">\n",
    "\n",
    "<h3><i>« Prédire est difficile, surtout lorsqu’il s’agit de l’avenir »</i></h3><br/>\n",
    "<div style=\"margin-left:450px\">proverbe danois</div>\n",
    "\n",
    "<hr style=\"height:1px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des bibliothèques utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importation des bibliothèques\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Bibliothèques importées!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Données\n",
    "\n",
    "### Dépôt de données ouvertes du COVID-19 - John Hopkins University\n",
    "\n",
    "\n",
    "https://github.com/CSSEGISandData/COVID-19\n",
    "\n",
    "<img src=\"\" style=\"width: 100%;float:center;\"/>\n",
    "\n",
    "**Note** : Les données contenues dans le répertoire DATA doivent être mise à jour régulièrement pour refléter l'évolution de la pandémie dans le temps. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture des données\n",
    "\n",
    "Nous nous intéressons au fichier `time_series_19-covid-Confirmed.csv` qui contient les données sur les cas confirmés de COVID-19\n",
    "\n",
    "wget --no-check-certificate https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv?raw=True -O time_series_covid19_confirmed_global.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note - bonne pratique de postfixer les Dataframe par _df (Rappel: Python n'est pas typé)\n",
    "series_chronologiques_COVID19_df = pd.read_csv('DATA/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv',sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_chronologiques_COVID19_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrait d'attributs «superflus»\n",
    "\n",
    "Puisque nous nous intéressons à l'évolution du nombre de malades dans le temps, certains attributs (colonnes du tableau de données) sont superflus ou «inutiles» et alourdissent notre analyse.\n",
    "\n",
    "Ci-dessous une liste d'attributs à retirer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attributs_a_retirer = [\"Lat\",\"Long\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirer les attributs «superflus» avec la fonction `.drop()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_chronologiques_COVID19_df = series_chronologiques_COVID19_df.drop(attributs_a_retirer,axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_chronologiques_COVID19_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maintenant, examinons les données pour les différentes provinces canadiennes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_chronologiques_COVID19_df[series_chronologiques_COVID19_df['Country/Region']==\"Canada\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'une entrée supplémentaire spécifique pour le Québec (avec accent aigu) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quebec_df = series_chronologiques_COVID19_df[(series_chronologiques_COVID19_df['Country/Region']==\"Canada\") & \n",
    "                                (series_chronologiques_COVID19_df['Province/State']==\"Quebec\")]\n",
    "\n",
    "quebec_df.loc[52,'Country/Region'] = 'Québec'\n",
    "quebec_df.loc[52,'Province/State'] = np.nan\n",
    "\n",
    "series_chronologiques_COVID19_df = series_chronologiques_COVID19_df.append(quebec_df , ignore_index=True)\n",
    "series_chronologiques_COVID19_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regroupement des données des états et provinces\n",
    "**Note** : Pour avoir un total par pays, nous allons regrouper les états et les provinces d'un même pays. Utilisaton des fonctions `.groupby()` et `.sum()`. Aussi `.reset_index()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_chronologiques_COVID19_df = series_chronologiques_COVID19_df.groupby(['Country/Region']).sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions que le regroupement est bien effectué, avec les données sur le Canada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series_chronologiques_COVID19_df[series_chronologiques_COVID19_df['Country/Region']==\"Canada\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series = series_chronologiques_COVID19_df[series_chronologiques_COVID19_df['Country/Region']==\"Québec\"]\n",
    "series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correction d'une erreur dans les données du 4 avril 2020\n",
    "series_chronologiques_COVID19_df.loc[140,'4/4/20']=6997\n",
    "# Correction des données du 25 et 26 décembre 2020\n",
    "series_chronologiques_COVID19_df.loc[140,'12/25/20']=185872+2235\n",
    "series_chronologiques_COVID19_df.loc[140,'12/26/20']=185872+4492\n",
    "# 2 808 nouveaux cas pour le 31 décembre, 1 986 pour le 1er janvier et de 2 869 pour le 2 janvier, \n",
    "series_chronologiques_COVID19_df.loc[140,'12/31/20']=199822+2808\n",
    "series_chronologiques_COVID19_df.loc[140,'1/1/21']=199822+2808+1986\n",
    "series_chronologiques_COVID19_df.loc[140,'1/2/21']=199822+2808+1986+2869\n",
    "series_chronologiques_COVID19_df[series_chronologiques_COVID19_df['Country/Region']==\"Quebec\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèles prédictifs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L'évolution de l'épidémie au Québec\n",
    "Pour des raisons évidente d'intérêt, je me concentrerai sur la prévision de l'évolution de l'épidémie au Québec\n",
    "\n",
    "Rappel de la série chonologique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(list(series))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parser(x):\n",
    "    return pd.datetime.strptime(x, '%m/%d/%y')\n",
    "\n",
    "series_raw = series_chronologiques_COVID19_df[series_chronologiques_COVID19_df['Country/Region']=='Québec']\n",
    "print(series_raw)\n",
    "dates_list = [parser(x) for x in list(series_raw.columns[1:])]\n",
    "values_list = list((series_raw.values)[0][1:])\n",
    "# Ici au besoin, on peut ajouter manuellement un nouveau point de données\n",
    "# lignes commentées\n",
    "# values_list += [15857]\n",
    "# dates_list += [parser('4/16/20')]                     \n",
    "print(\"-\"*90)\n",
    "print(\"values_list[-10:]:\")\n",
    "print(list(values_list[-10:]))\n",
    "print(\"*\"*90)\n",
    "print(\"dates_list[-10:]:\")\n",
    "print(dates_list[-10:])\n",
    "print(\"-\"*90)\n",
    "series = pd.Series(values_list,index=dates_list)\n",
    "series.index.name = 'date'\n",
    "print(\"series[-10:]:\")\n",
    "print(list(series)[-10:])\n",
    "print(\"-\"*90)\n",
    "print(\"series.index[-10:]:\")\n",
    "print(list(series.index)[-10:])\n",
    "print(\"*\"*90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage de la progression temporelle du nombre de malades confirmés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nombre_dor = 1.618\n",
    "hauteur = 12\n",
    "longueur = int(nombre_dor * hauteur)\n",
    "\n",
    "plt.figure(figsize=(longueur/2,hauteur/2))\n",
    "series.plot()\n",
    "plt.title(\"Évolution du nombre de malades confirmés au Québec\",fontsize=18)\n",
    "plt.xlabel(\"date\",fontsize=18)\n",
    "plt.ylabel(\"nombre de malades confirmés - échelle linéaire\",fontsize=14)\n",
    "xticks(rotation=60)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(longueur/2,hauteur/2))\n",
    "xticks(rotation=60)\n",
    "ax.set_yscale('log')\n",
    "series.plot()\n",
    "plt.title(\"Évolution du nombre de malades confirmés au Québec\",fontsize=18)\n",
    "plt.xlabel(\"date\",fontsize=18)\n",
    "plt.ylabel(\"nombre de malades confirmés - échelle log\",fontsize=16)\n",
    "xticks(rotation=60)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Modèle simple basé sur une régression et une fonction exponentielle\n",
    " ### Modéliser avec une fonction exponentielle de forme $a e^{bx}+c$ avec la fonction <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html\">`scipy.optimize.curve_fit`</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nbre_points = 20\n",
    "print(series[-nbre_points:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "y_data = np.array([y for y in series[-nbre_points:].values if y > 0])\n",
    "x_data = np.array([x for x in range(len(y_data))])\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return a * np.exp(b * x) + c\n",
    "\n",
    "popt, pcov = curve_fit(func, x_data, y_data, maxfev=5000)\n",
    "print(popt)\n",
    "\n",
    "plt.figure(figsize=(longueur/2,hauteur/2))\n",
    "plt.title(\"Régression appliquée à une fonction exponentielle\\n $a e^{bx}+c$\",fontsize=18)\n",
    "plt.xlabel(\"nombre de jours\",fontsize=18)\n",
    "plt.ylabel(\"nombre de malades\",fontsize=18)\n",
    "\n",
    "plt.scatter(x_data, y_data)\n",
    "\n",
    "_ = plt.plot(x_data, func(x_data, *popt), 'b--',\n",
    "             label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_xdata_predictions(x_data,n_predictions):\n",
    "    longueur_x_data = len(x_data)    \n",
    "    return [nouv_x for nouv_x in range(longueur_x_data,longueur_x_data+n_predictions)]\n",
    "    \n",
    "n_predictions = 3\n",
    "x_data_list_extended = x_data.tolist() + generate_xdata_predictions(x_data,n_predictions)\n",
    "x_data_extended = np.array(x_data_list_extended)\n",
    "print(list(x_data_extended))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(longueur/2,hauteur/2))\n",
    "plt.title(\"Régression appliquée à une fonction exponentielle\\n $a e^{bx}+c$\",fontsize=18)\n",
    "plt.xlabel(\"nombre de jours\",fontsize=18)\n",
    "plt.ylabel(\"nombre de malades\",fontsize=18)\n",
    "\n",
    "predictions = func(x_data_extended, *popt)\n",
    "\n",
    "plt.scatter(x_data, y_data)\n",
    "\n",
    "print(\"-\"*90)\n",
    "print(\"Vraies valeurs:\")\n",
    "for index in range(len(y_data)):\n",
    "    print('x=%i, y=%i' % (index,y_data[index]))\n",
    "print(\"-\"*90)\n",
    "\n",
    "plt.scatter(x_data_extended[-n_predictions:], predictions[-n_predictions:],marker=\"x\",color=\"r\")\n",
    "\n",
    "_ = plt.plot(x_data_extended, predictions, 'b--',\n",
    "             label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"-\"*90)\n",
    "print(\"Prédictions:\")\n",
    "for index in range(len(x_data),len(x_data_extended)):\n",
    "    print('x=%i, y=%i' % (index,predictions[index]))\n",
    "print(\"-\"*90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction_regNonLin_exp = int(predictions[len(x_data)])\n",
    "prediction_regNonLin_exp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle ARIMA\n",
    "\n",
    "Une méthode statistique populaire pour la prévision des séries chronologiques est le modèle ARIMA, un acronyme qui signifie AutoRegressive Integrated Moving Average, en français modèle de moyenne mobile autorégressive. Il s'agit d'une classe de modèle qui capture une suite de différentes structures temporelles dans les données d'une série chronologique. \n",
    "\n",
    "Trois hyperparamètres contrôlent l'algorithme ARIMA \n",
    "\n",
    "* p: l'ordre du modèle autorégressif (correspond au nombre de périodes antérieuses considérées)\n",
    "* d: le degré de différenciation des observations brutes (soustraction d'une observation au temps t à une observation à la période de temps précédente t-1) afin de rendre la série chronologique stationnaire\n",
    "* q: l'ordre de la moyenne mobile (dépendance entre une observation et l'erreur résiduelle d'une moyenne mobile apppliquée aux observations antérieures) \n",
    "\n",
    "Référence : \n",
    "\n",
    "* https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average\n",
    "\n",
    "* https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrélation\n",
    "Nous pouvons calculer la corrélation pour les observations de séries chronologiques avec des observations avec des périodes de temps précédentes, appelés périodes antérieures (en anglais, lag). Étant donné que la corrélation des observations de la série chronologique est calculée avec des valeurs de la même série à des périodes antérieures, cela s'appelle une autocorrélation, (en anglais. Autocorrelation Function, ACF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous, calcul et affichage de l'autocorrélation avec la fonction `.autocorrelation_plot()` de la bibliothèque Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "plt.figure(figsize=(longueur/2,hauteur/2))\n",
    "autocorrelation_plot(series)\n",
    "plt.xlabel(u'Périodes antérieures',fontsize=18)\n",
    "plt.ylabel(u'Autocorrélation',fontsize=18)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le même calcul et affichage de l'autocorrélation avec la fonction `.plot_acf()` de la bibliothèque statsmodels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "fig, ax = plt.subplots(figsize=(longueur/2,hauteur/2))\n",
    "plot_acf(series,title='',ax=ax)\n",
    "plt.xlabel(u'Périodes antérieures',fontsize=18)\n",
    "plt.ylabel(u'Autocorrélation',fontsize=18)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrélation partielle\n",
    "Une autocorrélation partielle (en anglais. Partial Autocorrelation Function, PACF) est un résumé de la relation entre une observation dans une série chronologique avec des observations à des périodes antérieures en supprimant les relations des observations intermédiaires. Utilisation de avec la fonction `.plot_pacf()` de la bibliothèque statsmodels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "fig, ax = plt.subplots(figsize=(longueur/2,hauteur/2))\n",
    "try:\n",
    "    plot_pacf(series,title='',ax=ax)\n",
    "    plt.xlabel(u'Périodes antérieures',fontsize=18)\n",
    "    plt.ylabel(u'Autocorrelation',fontsize=18)\n",
    "    plt.show()\n",
    "except:\n",
    "    print(\"Matrice singulière\")\n",
    "    # Ajout de bruit\n",
    "    series = series+1.0e-09*np.random.rand(series.shape[0])\n",
    "    plot_pacf(series,title='',ax=ax)\n",
    "    plt.xlabel(u'Périodes antérieures',fontsize=18)\n",
    "    plt.ylabel(u'Autocorrelation',fontsize=18)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto ARIMA\n",
    "\n",
    "Auto ARIMA calcule les meilleurs modèles ARIMA à partir des données et de contraintes sur les hyperparamètres (p,d,q) de ARIMA selon diférents critères comme le <a href=\"https://fr.wikipedia.org/wiki/Crit%C3%A8re_d%27information_d%27Akaike\">critère d'information d'Akaike</a> (Akaike information criterion ou AIC) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install pmdarima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installer la bibliothèque Python auto_arima\n",
    "\n",
    "#> sudo pip3 install pyramid-arima - deprecated\n",
    "\n",
    "   > sudo pip3 install pmdarima\n",
    "   \n",
    "Documentation: https://alkaline-ml.com/pmdarima/0.9.0/tips_and_tricks.html#tips-and-tricks\n",
    "\n",
    "Prise en main rapide: https://alkaline-ml.com/pmdarima/0.9.0/quickstart.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import sys\n",
    "\n",
    "sortie_standard = sys.stdout\n",
    "sortie_autoarima = StringIO()\n",
    "sys.stdout =  sortie_autoarima\n",
    "\n",
    "# import pyramid as pm - deprecated\n",
    "import pmdarima as pm\n",
    "print(\"pmdarima version:\",pm.__version__)\n",
    "print()\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Entraîner auto-ARIMA\n",
    "meilleur_ARIMA = pm.auto_arima(series, start_p=1, start_q=1,\n",
    "                               max_p=3, max_q=3, m=100,\n",
    "                               start_P=0, seasonal=False,\n",
    "                               d=1, D=1, trace=True,\n",
    "                               error_action='ignore',  # pas de message d'erreur sur\n",
    "                               suppress_warnings=True, # pas de message de non convergence\n",
    "                               stepwise=True)  # calcul pas à pas\n",
    "\n",
    "# Restaurer la sortie standard\n",
    "sys.stdout = sortie_standard\n",
    "\n",
    "# Récupérer la sortie autoarima \n",
    "sortie_autoarima_str = sortie_autoarima.getvalue()\n",
    "\n",
    "print(sortie_autoarima_str)\n",
    "\n",
    "meilleur_ARIMA.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "liste_resultats_ARIMA = sortie_autoarima_str.split('\\n')\n",
    "# motif_extraction = \"order=\\((\\d),\\s(\\d),\\s(\\d)\\);\\s*AIC=(\\d*\\.\\d*|nan)\" \n",
    "motif_extraction = \"ARIMA\\((\\d),(\\d),(\\d)\\).*AIC=(\\d*\\.\\d*|nan)\" \n",
    "\n",
    "p = re.compile(motif_extraction)\n",
    "\n",
    "meilleurs_ARIMA_dict = {}\n",
    "for resultat_ARIMA_brut in liste_resultats_ARIMA:\n",
    "    if p.findall(resultat_ARIMA_brut):\n",
    "        resultat_ARIMA = p.findall(resultat_ARIMA_brut)[0]\n",
    "        arima_etiq = \"_\".join(resultat_ARIMA[:3])\n",
    "        aic = resultat_ARIMA[3]\n",
    "        if aic == \"nan\":\n",
    "            aic = 10000000\n",
    "        meilleurs_ARIMA_dict[arima_etiq]=int(float(aic))\n",
    "meilleurs_ARIMA_list = list({k: v for k, v in sorted(meilleurs_ARIMA_dict.items(), key=lambda item: item[1])})\n",
    "#meilleurs_ARIMA_list[:2]\n",
    "\n",
    "meilleurs_ARIMA = []\n",
    "#for meilleur_arima in meilleurs_ARIMA_list[:2]:\n",
    "for meilleur_arima in meilleurs_ARIMA_list:\n",
    "    print(meilleur_arima.split('_'))\n",
    "    meilleurs_ARIMA += [tuple([int(carac) for carac in meilleur_arima.split('_')])]\n",
    "meilleurs_ARIMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meilleurs_ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement du meilleur modèle ARIMA\n",
    "\n",
    "Le critère de sélection selon le <a href=\"https://fr.wikipedia.org/wiki/Crit%C3%A8re_d%27information_d%27Akaike\">critère d'information d'Akaike</a> (Akaike information criterion ou AIC). On ne conserve que les deux ou trois meilleurs modèles ARIMAselon ce critère qui doit être minimisé.\n",
    "\n",
    "Certains modèles ARIMA sont retirés car ils ne convergent pas (`LinAlgError: SVD did not converge`) ou parce que le modèle n'est pas stationnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy.linalg import LinAlgError\n",
    "from math import sqrt\n",
    "\n",
    "X = series.values\n",
    "X = [x for x in X if x > 0]\n",
    "\n",
    "# Ici au besoin, on peut ajouter manuellement un nouveau point de données\n",
    "# X += [3430]\n",
    "taille_entrainement_data = int(len(X) * 0.66)\n",
    "\n",
    "# Séparation entre jeu de données d'entraînement et jeu de données de test\n",
    "entrainement_data, test_data = X[0:taille_entrainement_data], X[taille_entrainement_data:len(X)]\n",
    "\n",
    "predictions_ARIMA = {}\n",
    "print(\"*\"*90)\n",
    "\n",
    "for meilleur_ARIMA in meilleurs_ARIMA:\n",
    "    drapeau_erreur = False\n",
    "    historique = [x for x in entrainement_data]\n",
    "    predictions = list()\n",
    "    nbr_predictions = 3\n",
    "    nbr_jours_init = len(X)-len(test_data)\n",
    "\n",
    "    for t in range(len(test_data)+nbr_predictions):\n",
    "        try:\n",
    "            print(\"Modèle meilleur_ARIMA:\",meilleur_ARIMA)\n",
    "            modele_ARIMA = ARIMA(historique, order=meilleur_ARIMA)\n",
    "            # modele_ARIMA_entraine = modele_ARIMA.fit(disp=0)\n",
    "            modele_ARIMA_entraine = modele_ARIMA.fit()\n",
    "            sortie = modele_ARIMA_entraine.forecast()\n",
    "            une_prediction = sortie[0]\n",
    "            predictions.append(une_prediction)\n",
    "            if t < len(test_data):\n",
    "                vraie_valeur = test_data[t]\n",
    "                historique.append(vraie_valeur)\n",
    "                print('Nombre de jours écoulés=%i, t=%i, prédiction=%i, vraie valeur=%i' % (nbr_jours_init+t,t,une_prediction,vraie_valeur))\n",
    "            else:\n",
    "                historique.append(une_prediction)\n",
    "                print(\"meilleur_ARIMA\",meilleur_ARIMA)\n",
    "                etiq_ARIMA = \"_\".join([str(hyperparam) for hyperparam in meilleur_ARIMA])\n",
    "                if not etiq_ARIMA in predictions_ARIMA.keys():\n",
    "                    predictions_ARIMA[etiq_ARIMA]=int(une_prediction)\n",
    "                print('Nombre de jours écoulés=%i, t=%i, prédiction=%i' % (nbr_jours_init+t,t,une_prediction))\n",
    "        except:\n",
    "            print(\"*** Erreur! ***\")\n",
    "            drapeau_erreur = True\n",
    "            break\n",
    "    if drapeau_erreur:\n",
    "        continue\n",
    "    else:   \n",
    "        # Évaluation de l'erreur de prédiction\n",
    "        rmse = sqrt(mean_squared_error(test_data, predictions[:-nbr_predictions]))\n",
    "        print('Test RMSE: %.3f' % rmse)\n",
    "        # Afficher les vraies valeurs et les prédictions pour le jeu de données de test\n",
    "        plt.figure(figsize=(longueur/2,hauteur/2))\n",
    "        date = (dates_list[-1]+pd.Timedelta(days=1)).strftime(\"%d-%m-%Y\")\n",
    "        plt.title(u\"Prédictions pandémie COVID-19 - Québec - \" + date + \"\\n\" + \n",
    "                  \"modèle ARIMA (\" + etiq_ARIMA.replace(\"_\",\", \") + \")\\n\",fontsize=18)\n",
    "        x_data = list(range(len(test_data)))\n",
    "        x_data_extension = list(range(len(test_data)+nbr_predictions))[-nbr_predictions:]\n",
    "        plt.scatter(x_data,test_data)\n",
    "        plt.plot(test_data,color='blue',label=\"vraies valeurs\")\n",
    "        plt.plot(x_data_extension[-nbr_predictions:],\n",
    "                 predictions[-nbr_predictions:],\n",
    "                 \"r--\",marker=\"x\",label=\"prédictions\")\n",
    "        point1 = [x_data[-1], test_data[-1]]\n",
    "        point2 = [x_data_extension[0],int(predictions[-nbr_predictions])]\n",
    "        x_values = [point1[0], point2[0]]\n",
    "        y_values = [point1[1], point2[1]]\n",
    "        plt.plot(x_values, y_values,\"r--\",marker=\"x\")\n",
    "        plt.legend(loc='best',fontsize=14)\n",
    "        plt.xlabel(\"nombre de jours\",fontsize=18)\n",
    "        plt.ylabel(\"nombre de malades\",fontsize=18)\n",
    "        plt.show()\n",
    "        print(\"*\"*90)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afficher les vraies valeurs et la prédiction pour demain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle meilleurs ARIMA seulement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Composante du modèle exponentiel\n",
    "ponderation_exp = 0\n",
    "total_predictions = prediction_regNonLin_exp * ponderation_exp\n",
    "#total_predictions = 0 \n",
    "# print(\"Prédictions régr. non-lin.: \",prediction_regNonLin_exp)\n",
    "for etiq_ARIMA in predictions_ARIMA.keys():\n",
    "    print(\"Prédictions ARIMA: (\" + etiq_ARIMA.replace(\"_\",\", \") + \") : \" + str(predictions_ARIMA[etiq_ARIMA]))\n",
    "    total_predictions += predictions_ARIMA[etiq_ARIMA]\n",
    "print(\"Prédictions pour \"+(dates_list[-1]+pd.Timedelta(days=1)).strftime(\"%d-%m-%Y\"))\n",
    "# Modèle exponentiel utilisé avant le 1er avril 2020\n",
    "# ligne commentée\n",
    "prediction_pur_ARIMA = int(total_predictions/(len(predictions_ARIMA)+1*ponderation_exp))\n",
    "print(\" => \",prediction_pur_ARIMA,\" <= \")\n",
    "#print(\" => \",int(total_predictions/len(predictions_ARIMA)),\" <= \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afficher les vraies valeurs et la prédiction pour demain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modèle meilleurs ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(longueur/2,hauteur/2))\n",
    "date_demain = (dates_list[-1]+pd.Timedelta(days=1)).strftime(\"%d-%m-%Y\")\n",
    "prediction_demain = prediction_pur_ARIMA\n",
    "x_data = list(range(len(test_data)))\n",
    "x_data_extension = list(range(len(test_data)+nbr_predictions))[-nbr_predictions:]\n",
    "plt.scatter(x_data,test_data)\n",
    "plt.plot(test_data,color='blue',label=\"vraies valeurs\")\n",
    "point1 = [x_data[-1], test_data[-1]]\n",
    "point2 = [x_data_extension[0],prediction_demain]\n",
    "x_values = [point1[0], point2[0]]\n",
    "y_values = [point1[1], point2[1]]\n",
    "plt.plot(x_values, y_values,\"r--\",marker=\"x\",label=\"prédiction\")\n",
    "plt.axhline(prediction_demain,linestyle='--',linewidth=0.5,color='r')\n",
    "plt.axvline(x=point2[0],linestyle='--',linewidth=0.5,color='r')\n",
    "plt.text(point2[0]-0.5, point2[1], date_demain + \"\\n\" +\" \"*6 + str(prediction_demain),fontsize=12)\n",
    "plt.plot(x_values, y_values,\"r--\",marker=\"x\")\n",
    "xlim(right=point2[0]+x_values[-1]/6)\n",
    "ylim(top=point2[1]+y_values[-1]/15)\n",
    "plt.legend(loc='best',fontsize=14)\n",
    "plt.xlabel(\"nombre de jours\",fontsize=18)\n",
    "plt.ylabel(\"nombre de malades\",fontsize=18)\n",
    "plt.title(u\"Prédiction pandémie COVID-19 - Québec - pour le \" + date_demain + \"\\n\" + \n",
    "          \"modèle ARIMA => nouveaux malades: \" + str(prediction_demain-test_data[-1]) + \" - Total: \"+ str(prediction_demain) + \" <=\\n,fontsize=18)\n",
    "plt.savefig('images/Prediction-ARIMA_seul-COVID19-Quebec.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle combiné \n",
    "\n",
    "Moyenne des prédictions du meilleur modèle ARIMA plus une partie exponentielle issue d'un calcul de régression non linéaire. \n",
    "\n",
    "<!--\n",
    "Les résultats depuis quelques mois semblent confirmer que le modèle combiné est plus réaliste, du moins à ce stade de l'épidémie au Québec.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Composante du modèle exponentiel\n",
    "ponderation_exp = 1.0\n",
    "ponderation_arima = 9.0\n",
    "total_predictions = prediction_regNonLin_exp * ponderation_exp\n",
    "print(\"Prédictions régr. non-lin.: \",prediction_regNonLin_exp-y_data[-1])\n",
    "print(\"Prédictions pur ARIMA: \",prediction_pur_ARIMA-y_data[-1])\n",
    "total_predictions += prediction_pur_ARIMA*ponderation_arima\n",
    "print(\"Prédictions pour \"+(dates_list[-1]+pd.Timedelta(days=1)).strftime(\"%d-%m-%Y\"))\n",
    "# Modèle exponentiel utilisé avant le 1er avril 2020\n",
    "# ligne commentée\n",
    "prediction_modele_combine = int(total_predictions/(ponderation_exp+ponderation_arima))\n",
    "print(\"Prédictions modèle combiné: \",prediction_modele_combine-y_data[-1])\n",
    "print(\"Nouveaux malades => \",prediction_modele_combine-y_data[-1],\" <= \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(longueur/2,hauteur/2))\n",
    "date_demain = (dates_list[-1]+pd.Timedelta(days=1)).strftime(\"%d-%m-%Y\")\n",
    "prediction_demain = prediction_modele_combine\n",
    "x_data = list(range(len(test_data)))\n",
    "x_data_extension = list(range(len(test_data)+nbr_predictions))[-nbr_predictions:]\n",
    "plt.scatter(x_data,test_data)\n",
    "plt.plot(test_data,color='blue',label=\"vraies valeurs\")\n",
    "point1 = [x_data[-1], test_data[-1]]\n",
    "point2 = [x_data_extension[0],prediction_demain]\n",
    "x_values = [point1[0], point2[0]]\n",
    "y_values = [point1[1], point2[1]]\n",
    "plt.plot(x_values, y_values,\"r--\",marker=\"x\",label=\"prédiction\")\n",
    "plt.axhline(prediction_demain,linestyle='--',linewidth=0.5,color='r')\n",
    "plt.axvline(x=point2[0],linestyle='--',linewidth=0.5,color='r')\n",
    "plt.text(point2[0]-0.5, point2[1], date_demain + \"\\n\" +\" \"*6 + str(prediction_demain),fontsize=12)\n",
    "plt.plot(x_values, y_values,\"r--\",marker=\"x\")\n",
    "xlim(right=point2[0]+x_values[-1]/6)\n",
    "ylim(top=point2[1]+y_values[-1]/15)\n",
    "plt.legend(loc='best',fontsize=14)\n",
    "plt.xlabel(\"nombre de jours\",fontsize=18)\n",
    "plt.ylabel(\"nombre de malades\",fontsize=18)\n",
    "plt.title(u\"Prédiction pandémie COVID-19 - Québec - pour le \" + date_demain + \"\\n\" + \n",
    "          \"modèle combiné exp.+ARIMA => nouveaux cas: \" + str(prediction_demain-test_data[-1]) + \" - Total: \"+ str(prediction_demain) + \" <=\\n\",fontsize=18)\n",
    "plt.savefig('images/Prediction-modele_combine-COVID19-Quebec.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Fin du carnet IPython\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
